"""
Adaptive Question Generation Agent

Generates adaptive multiple-choice questions using:
- LLMs (Groq) when available
- Dynamic fallback generation when LLM is unavailable

Designed to be:
- Pylint clean (â‰ˆ10/10)
- Free of circular imports
- Deterministic in structure, random in content
"""

from __future__ import annotations

import json
import logging
import random
import re
import time
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Optional


# LOGGING

logging.basicConfig(level=logging.INFO)
LOGGER = logging.getLogger(__name__)


# ENUMS

class DifficultyLevel(Enum):
    """Difficulty levels for questions."""

    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"


class QuestionType(Enum):
    """Supported question types."""

    MULTIPLE_CHOICE = "multiple_choice"



# DATA MODELS

@dataclass(slots=True)
class UserContext:
    """Represents user performance and behavior context."""

    user_id: str
    current_score: float
    questions_attempted: int
    correct_answers: int
    average_response_time: float
    current_streak: int
    weak_topics: List[str]
    strong_topics: List[str]
    confidence_level: float
    engagement_level: float
    stress_indicators: float


@dataclass(slots=True)
class VisualCues:
    """Represents optional visual analysis signals."""

    eye_contact: float
    attention_level: float
    stress_indicators: float
    confidence_level: float
    distraction_count: int
    posture_score: float


@dataclass(slots=True)
class Question:
    """Represents a generated assessment question."""

    id: str
    type: QuestionType
    topic: str
    difficulty: DifficultyLevel
    question_text: str
    options: List[str]
    correct_answer: str
    explanation: str
    time_limit: int
    points: int



# UTILITIES

JSON_PATTERN = re.compile(r"\{.*\}", re.DOTALL)


def safe_json_parse(text: str) -> Dict:
    """
    Safely parse JSON from LLM output.

    Args:
        text: Raw text returned by LLM

    Returns:
        Parsed JSON dictionary

    Raises:
        ValueError: If JSON cannot be parsed
    """
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        match = JSON_PATTERN.search(text)
        if not match:
            raise ValueError("No valid JSON found in LLM response") from None
        return json.loads(match.group())



# ADAPTIVE AGENT

class AdaptiveQuestionAgent:
    """Core adaptive question generation engine."""

    _POINTS_MAP = {
        DifficultyLevel.EASY: 5,
        DifficultyLevel.MEDIUM: 10,
        DifficultyLevel.HARD: 15,
    }

    def __init__(self, llm_providers: Dict[str, object]) -> None:
        """
        Initialize agent.

        Args:
            llm_providers: Dictionary of initialized LLM clients
        """
        self._llm_providers = llm_providers or {}

    
    # PUBLIC API
    
    def generate_adaptive_question(
        self,
        user_context: UserContext,
        visual_cues: Optional[VisualCues] = None,
        preferred_topics: Optional[List[str]] = None,
    ) -> Question:
        """
        Generate a new adaptive question.

        LLM is preferred. Dynamic fallback is guaranteed to produce
        unique questions when LLM is unavailable.

        Args:
            user_context: User performance context
            visual_cues: Optional visual feedback
            preferred_topics: Optional topic preferences

        Returns:
            Question object
        """
        topic = (
            random.choice(preferred_topics)
            if preferred_topics
            else "programming"
        )

        difficulty = self._select_difficulty(user_context, visual_cues)

        try:
            return self._generate_llm_question(topic, difficulty)
        except Exception as exc:  # noqa: BLE001 (intentional fallback)
            LOGGER.warning(
                "LLM unavailable, using fallback: %s",
                exc,
            )
            return self._generate_fallback_question(topic, difficulty)

    
    # DIFFICULTY SELECTION
    
    @staticmethod
    def _select_difficulty(
        user_context: UserContext,
        visual_cues: Optional[VisualCues],
    ) -> DifficultyLevel:
        """Select difficulty based on performance and stress."""
        if visual_cues and visual_cues.stress_indicators > 0.7:
            return DifficultyLevel.EASY

        if user_context.current_score >= 0.75:
            return DifficultyLevel.HARD
        if user_context.current_score >= 0.5:
            return DifficultyLevel.MEDIUM

        return DifficultyLevel.EASY

    
    # LLM GENERATION
    
    def _generate_llm_question(
        self,
        topic: str,
        difficulty: DifficultyLevel,
    ) -> Question:
        """Generate question using Groq LLM."""
        client = self._llm_providers.get("groq")
        if client is None:
            raise RuntimeError("Groq LLM not configured")

        prompt = (
            f"Generate a UNIQUE {difficulty.value} multiple-choice question "
            f"about {topic}. Return ONLY valid JSON:\n"
            "{"
            '"question_text": "...", '
            '"options": ["A", "B", "C", "D"], '
            '"correct_answer": "A", '
            '"explanation": "..."'
            "}"
        )

        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            temperature=random.uniform(0.8, 0.95),
            max_tokens=400,
        )

        data = safe_json_parse(response.choices[0].message.content)

        return Question(
            id=f"q_{int(time.time() * 1000)}_{random.randint(1000, 9999)}",
            type=QuestionType.MULTIPLE_CHOICE,
            topic=topic,
            difficulty=difficulty,
            question_text=data["question_text"],
            options=data["options"],
            correct_answer=data["correct_answer"],
            explanation=data["explanation"],
            time_limit=30,
            points=self._POINTS_MAP[difficulty],
        )

    
    # FALLBACK GENERATION
    
    def _generate_fallback_question(
        self,
        topic: str,
        difficulty: DifficultyLevel,
    ) -> Question:
        """Generate dynamic fallback question with guaranteed variation."""
        concept_pool = {
            DifficultyLevel.EASY: [
                "variable", "loop", "function", "string", "integer",
                "boolean", "list", "dictionary", "comment", "operator",
            ],
            DifficultyLevel.MEDIUM: [
                "recursion", "algorithm", "API", "OOP", "inheritance",
                "polymorphism", "encapsulation", "exception handling",
                "list comprehension", "REST API",
            ],
            DifficultyLevel.HARD: [
                "binary search", "merge sort", "quick sort",
                "Big-O notation", "memoization", "deadlock",
                "threading", "CAP theorem",
                "database indexing", "normalization",
            ],
        }

        templates = (
            "Which option best describes {concept}?",
            "What is the primary purpose of {concept}?",
            "Which statement about {concept} is correct?",
            "In programming, {concept} is mainly used to?",
            "Which scenario best demonstrates {concept}?",
        )

        incorrect_pool = (
            "Improve UI design",
            "Manage network hardware",
            "Render graphics",
            "Compile source code",
            "Handle operating system interrupts",
        )

        concept = random.choice(concept_pool[difficulty])
        question_text = random.choice(templates).format(concept=concept)

        correct_answer = f"Used in programming related to {concept}"
        options = random.sample(incorrect_pool, 3) + [correct_answer]
        random.shuffle(options)

        return Question(
            id=f"fallback_{int(time.time() * 1000)}_{random.randint(1000, 9999)}",
            type=QuestionType.MULTIPLE_CHOICE,
            topic=topic,
            difficulty=difficulty,
            question_text=question_text,
            options=options,
            correct_answer=correct_answer,
            explanation=f"{concept.capitalize()} is a key programming concept.",
            time_limit=30,
            points=self._POINTS_MAP[difficulty],
        )



def create_adaptive_question_agent(
    llm_providers: Dict[str, object],
) -> AdaptiveQuestionAgent:
    """
    Factory method to create AdaptiveQuestionAgent.

    Args:
        llm_providers: Initialized LLM providers

    Returns:
        AdaptiveQuestionAgent instance
    """
    return AdaptiveQuestionAgent(llm_providers)
